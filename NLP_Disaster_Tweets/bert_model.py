# Author: Caleb Smith
# -*- coding: utf-8 -*-
"""bert_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c-BMgg9w0LKHfHdxfs3mXXv0WDgILQfn
"""
# Dependencies: pandas, transformers, datasets, torch

import pandas as pd
from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer
from datasets import Dataset
import torch

# Load dataframe
df = pd.read_csv("prepended_v3_lemmatized.csv")
df.drop(columns=['text', 'text_length', 'length'], inplace=True)
df.rename(columns={'processed_text':'text', 'target':'label'}, inplace=True)
df = df[["text", "label"]].copy()
df["text"] = df["text"].astype(str) # Force all entries to be strings

dataset = Dataset.from_pandas(df)

tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

def tokenize_function(example):
    return tokenizer(example["text"], truncation=True, padding="max_length", max_length=128)

dataset = dataset.map(tokenize_function, batched=True)
dataset = dataset.rename_column("label", "labels")
dataset.set_format("torch", columns=["input_ids", "attention_mask", "labels"])

dataset = dataset.train_test_split(test_size=0.2, seed=42)
train_dataset = dataset["train"]
eval_dataset = dataset["test"]

model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2)

training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    save_strategy="epoch",  # Add this!
    logging_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    save_total_limit=1,
    load_best_model_at_end=True,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    tokenizer=tokenizer,
)

trainer.train()

trainer.evaluate()

# Predict on new data
text = "The plot was really boring."
inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=128)
outputs = model(**inputs)
pred = torch.argmax(outputs.logits, dim=1).item()
print("Prediction:", pred)
