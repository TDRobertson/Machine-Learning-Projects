# Author: Caleb Smith
# -*- coding: utf-8 -*-
"""bertweet_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N87VqHVtVY5c9x5yNoY2uBCsHZ3wzRay
"""

# !pip install transformers datasets scikit-learn torch
# !pip install huggingface_hub[hf_xet] # I'm not entirely sure if this pip install is needed or not

import pandas as pd
import numpy as np
from transformers import BertTokenizer, BertForSequenceClassification
from datasets import Dataset
import torch
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn import metrics
from transformers import TrainingArguments, Trainer, AutoModelForSequenceClassification, AutoTokenizer

# Load dataframe
df = pd.read_csv("final_processed/prepended_v3_lemmatized.csv")
df.drop(columns=['text', 'text_length', 'length'], inplace=True)
df.rename(columns={'processed_text': 'text', 'target': 'label'}, inplace=True)
df = df[["text", "label"]].copy()  # Drop other columns if they exist
df["text"] = df["text"].astype(str)  # Force all entries to be strings
# df["text"] = df["text"].lower() # How do we do this the right way?
print(df.loc[0, "text"])

dataset = Dataset.from_pandas(df)


def compute_roc_auc(trainer, dataset):
    output = trainer.predict(dataset)
    probs = torch.nn.functional.softmax(torch.tensor(output.predictions), dim=-1)[:, 1].numpy()
    auc = metrics.roc_auc_score(output.label_ids, probs)
    return auc


tokenizer = AutoTokenizer.from_pretrained("vinai/bertweet-base", use_fast=False)


def tokenize_function(example):
    return tokenizer(example["text"], truncation=True, padding="max_length", max_length=128)


n = 5
kf = KFold(n_splits=n, shuffle=True, random_state=42)

acc_array_tr = []  # 'tr' is short for 'train'
f1_array_tr = []
precision_array_tr = []
recall_array_tr = []
auc_array_tr = []

acc_array_val = []
f1_array_val = []
precision_array_val = []
recall_array_val = []
auc_array_val = []

for train_index, val_index in kf.split(dataset):
    train = dataset[train_index]
    val = dataset[val_index]

    train = Dataset.from_dict(train)
    val = Dataset.from_dict(val)

    print(train)
    print(val)

    train = train.map(tokenize_function, batched=True)
    train = train.rename_column("label", "labels")
    train.set_format("torch", columns=["input_ids", "attention_mask", "labels"])

    val = val.map(tokenize_function, batched=True)
    val = val.rename_column("label", "labels")
    val.set_format("torch", columns=["input_ids", "attention_mask", "labels"])

    print(train)
    print(val)
    print(val['labels'])

    model = AutoModelForSequenceClassification.from_pretrained("vinai/bertweet-base", num_labels=2)

    training_args = TrainingArguments(
        output_dir="./results",
        eval_strategy="epoch",
        save_strategy="epoch",
        logging_strategy="epoch",
        report_to="none",
        learning_rate=2e-5,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        num_train_epochs=3,
        weight_decay=0.01,
        save_total_limit=1,
        load_best_model_at_end=True,
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train,
        eval_dataset=val,
        tokenizer=tokenizer,
    )

    trainer.train()
    trainer.evaluate()

    # Predict on training data
    train_output = trainer.predict(train)
    train_preds = np.argmax(train_output.predictions, axis=1)  # Convert logits to predicted class

    # Predict on test data
    val_output = trainer.predict(val)
    val_preds = np.argmax(val_output.predictions, axis=1)

    # True labels
    train_labels = train_output.label_ids
    val_labels = val_output.label_ids

    accuracy_tr = metrics.accuracy_score(train_labels, train_preds)
    f1_tr = metrics.f1_score(train_labels, train_preds)
    precision_tr = metrics.precision_score(train_labels, train_preds)
    recall_tr = metrics.recall_score(train_labels, train_preds)
    roc_auc_tr = compute_roc_auc(trainer, train)

    accuracy_val = metrics.accuracy_score(val_labels, val_preds)
    f1_val = metrics.f1_score(val_labels, val_preds)
    precision_val = metrics.precision_score(val_labels, val_preds)
    recall_val = metrics.recall_score(val_labels, val_preds)
    roc_auc_val = compute_roc_auc(trainer, val)

    acc_array_tr.append(accuracy_tr)
    f1_array_tr.append(f1_tr)
    precision_array_tr.append(precision_tr)
    recall_array_tr.append(recall_tr)
    auc_array_tr.append(roc_auc_tr)

    acc_array_val.append(accuracy_val)
    f1_array_val.append(f1_val)
    precision_array_val.append(precision_val)
    recall_array_val.append(recall_val)
    auc_array_val.append(roc_auc_val)

print("Training Accuracy Array: ")
print(acc_array_tr)
print("Training F1 Array: ")
print(f1_array_tr)
print("Training Precision Array: ")
print(precision_array_tr)
print("Training Recall Array: ")
print(recall_array_tr)
print("Training ROC_AUC Array: ")
print(auc_array_tr)

print("Training Accuracy mean: ")
print(np.mean(acc_array_tr))
print("Training F1 mean: ")
print(np.mean(f1_array_tr))
print("Training Precision mean: ")
print(np.mean(precision_array_tr))
print("Training Recall mean: ")
print(np.mean(recall_array_tr))
print("Training ROC_AUC mean: ")
print(np.mean(auc_array_tr))

print("Validation Accuracy Array: ")
print(acc_array_val)
print("Validation F1 Array: ")
print(f1_array_val)
print("Validation Precision Array: ")
print(precision_array_val)
print("Validation Recall Array: ")
print(recall_array_val)
print("Validation ROC_AUC Array: ")
print(auc_array_val)

print("Validation Accuracy mean: ")
print(np.mean(acc_array_val))
print("Validation F1 mean: ")
print(np.mean(f1_array_val))
print("Validation Precision mean: ")
print(np.mean(precision_array_val))
print("Validation Recall mean: ")
print(np.mean(recall_array_val))
print("Validation ROC_AUC mean: ")
print(np.mean(auc_array_val))
