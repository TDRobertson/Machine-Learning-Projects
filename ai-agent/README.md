## AI Agent (Gemini-based LLM Agent)

**Purpose**: This project is a simple AI Agent inspired by the Boot.dev curriculum. It acts as an LLM agent using Google's Gemini as the underlying pre-trained model via the `google-genai` SDK.

### What it does
- CLI that accepts a user prompt and returns a response generated by Gemini.
- Optional `--verbose` flag prints your prompt and token usage.

### Quick start
1. Requirements: Python 3.12+
2. Configure environment:
   - Create a `.env` file with `GEMINI_API_KEY=your_key_here`.
   - If running from the repo root, keep `.env` at the repo root. If running from inside `ai-agent/`, you can place `.env` there instead.
3. Install dependencies (choose one):
   - With uv (recommended):
     ```bash
     cd ai-agent
     uv sync
     uv run python main.py "Write a short haiku about code" --verbose
     ```
   - With Python directly from repo root:
     ```bash
     python ai-agent/main.py "Write a short haiku about code" --verbose
     ```

### Notes
- Uses: `google-genai`, `python-dotenv`.
- Model: `gemini-2.0-flash-001`.
- The `calculator/` subfolder contains a small CLI calculator demo and unit tests unrelated to the LLM agent.

### Utilities
- `functions/get_files_info.py`: returns a formatted listing for a directory in the form:
  `- README.md: file_size=1032 bytes, is_dir=False`
- Try it quickly via the helper script:
  ```bash
  python ai-agent/tests.py
  ```


